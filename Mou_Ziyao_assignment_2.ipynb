{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence\n",
    "# 464\n",
    "# Assignment #2\n",
    "\n",
    "## General Directions for this Assignment\n",
    "\n",
    "00. We're using a Jupyter Notebook environment (tutorial available here: https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html),\n",
    "01. Read the entire notebook before beginning your work, \n",
    "02. Output format should be exactly as requested, \n",
    "03. Each helper function should be preceeded by documentation (Markdown cell),\n",
    "05. No comments in the code; anything worth mentioning should be included in the documentation,\n",
    "06. Keep functions to 20 lines or less (including empty lines so do not add any),\n",
    "08. Use descriptive variable names,\n",
    "09. Functions should do only one thing,\n",
    "10. Check submission deadline on Gradescope, \n",
    "11. Rename the file to Last_First_assignment_2, \n",
    "12. Submit your notebook (as .ipynb, not PDF) using Gradescope, and\n",
    "13. Do not submit any other files.\n",
    "\n",
    "\n",
    "## Directions _not_ applicable for this Assignment:\n",
    "* Do not use classes,\n",
    "* Each helper function should be followed by three assert-style unit tests.\n",
    "\n",
    "\n",
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The World\n",
    "\n",
    "A `List of Lists` is used to represent the world. Cells marked as '‚¨õ' are obstacles in the world and are not traversable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2741,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = [\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨õ','‚¨õ','‚¨õ','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨õ','‚¨õ','‚¨õ','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨õ','‚¨õ','‚¨õ','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú'],\n",
    "['‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú','‚¨ú']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n"
     ]
    }
   ],
   "source": [
    "# A nicer view of the world, without commas and brackets\n",
    "for row in world:\n",
    "    print(\"\".join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot\n",
    "\n",
    "Our robot 'ü§ñ' starts at the bottom left and can either move up, down, left, or right. It needs to get to the '‚ù§Ô∏è' in the world. Unlike the previous assignment, the robot now knows where the heart is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2743,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVES = [(0,-1), (1,0), (0,1), (-1,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2744,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_start = (len(world)-1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2745,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal = (0, len(world)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bad Robot\n",
    "\n",
    "And unlike the previous assignment, we have a bad robot 'üëæ', too, that starts at the bottom right and can also move either up, down, left, or right. It wants to zap our robot. The zapper range isn't that great, so our robot is considered zapped if it is anywhere in a 3x3 cell centered at the bad robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 2746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_start = (len(world)-1, len(world)-1)\n",
    "bad_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the world with this information\n",
    "world[good_start[0]][good_start[1]] = 'ü§ñ'\n",
    "world[goal[0]][goal[1]] = '‚ù§Ô∏è'\n",
    "world[bad_start[0]][bad_start[1]] = 'üëæ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚ù§Ô∏è\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "ü§ñ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüëæ\n"
     ]
    }
   ],
   "source": [
    "# A nicer view of the world, without commas and brackets\n",
    "for row in world:\n",
    "    print(\"\".join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game\n",
    "\n",
    "* We have two players: our original good robot and the new bad robot 'üëæ'\n",
    "* At each turn of the game, a player gets to move in the world\n",
    "* Players only get to move according to `MOVES`\n",
    "* '‚¨õ' are obstacles that neither robot can traverse\n",
    "* Each player knows the other player's current location\n",
    "* 'ü§ñ' wants to get to the '‚ù§Ô∏è' without being zapped\n",
    "* 'üëæ' is trying to zap 'ü§ñ'\n",
    "* 'ü§ñ' wins if it gets to the '‚ù§Ô∏è'\n",
    "* 'üëæ' wins if it zaps the good robot\n",
    "* The game is over when either player wins or we've reached 82 plies (41 good robot moves and 41 bad robot moves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Search\n",
    "\n",
    "\n",
    "The MINIMAX pseudocode is as follows:\n",
    "\n",
    "```\n",
    "MINIMAX(state) returns action\n",
    "    return argmax action in Actions MIN-VALUE(RESULT(state,action))\n",
    "    \n",
    "\n",
    "MAX-VALUE(state) returns value\n",
    "if TERMINAL(state) return UTILITY(state)\n",
    "v <- -inf\n",
    "for each action in Actions(state)\n",
    "    v <- MAX(v, MIN-VALUE(RESULT(state, action))\n",
    "return v\n",
    "\n",
    "\n",
    "MIN-VALUE(state) returns value\n",
    "if TERMINAL(state) return UTILITY(state)\n",
    "v <- +inf\n",
    "for each action in Actions(state)\n",
    "    v <- MIN(v, MAX-VALUE(RESULT(state, action))\n",
    "return v\n",
    "```\n",
    "\n",
    "MINIMAX is used to model the opponent as a rational player that will also try it's best to win. When moves are simulated in the tree, that's just what they are, simulations. The actual board only changes once MINIMAX returns an action. You will probably need to maintain a deep copy of the world. Instead of going all the way to terminal nodes, use a depth parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #1\n",
    "\n",
    "\n",
    "Implement the game: players, actions, scores, keeping track of turns, when the game is over, how the world changes, and what strategy each player uses (random moves or MINIMAX). \n",
    "* 'ü§ñ' will use MINIMAX with a depth of 2 (simulate I move and then my opponent moves -- that's it) \n",
    "* 'üëæ' will choose actions at random. \n",
    "* 'ü§ñ' utility function = Euclidean distance to 'üëæ' - Euclidean distance to '‚ù§Ô∏è' (cares about getting to '‚ù§Ô∏è' and not being zapped by 'üëæ') \n",
    "* 'üëæ' utility function = - Euclidean distance to 'ü§ñ' (just cares about zapping 'ü§ñ')\n",
    "\n",
    "\n",
    "When the game is over, print out the world (nicer view) with the following changes:\n",
    "* Replace a '‚¨ú' with 'üü•' to indicate the path of 'üëæ', \n",
    "* Replace '‚¨ú' with 'üü©' to indicate the path of 'ü§ñ', and\n",
    "* 'ü§ñ', 'üëæ', '‚ù§Ô∏è', and '‚¨õ' are not replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your documentation, code, and tests start here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"breadth_first_search\"></a>\n",
    "## run_robot_game\n",
    "\n",
    "Description of your function.\n",
    "\n",
    "* **world** List[List[str]]: the search area\n",
    "* **good_start** Tuple[int, int]: the starting location of the good robot\n",
    "* **bad_start** Tuple[int, int]: the starting location of the bad robot\n",
    "* **goal** Tuple[int, int]: the goal location in the world\n",
    "* **moves** List[Tuple[int, int]]: the allowable moves in the world\n",
    "* **good_strategy** str: name of strategy to use for good robot: either random_strategy or MINIMAX with option to set depth\n",
    "* **bad_strategy** str: name of strategy to use for bad robot: either random_strategy or MINIMAX with option to set depth\n",
    "\n",
    "\n",
    "**returns** None (but prints out a nice view of the world and replaces appropriate cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2750,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: print_world\n",
    "\n",
    "**Description:**\n",
    "This function prints the game grid (world) in a readable format by joining the elements of each row of the grid into a string and printing them. Each row is displayed as a continuous sequence of symbols, representing the state of the game world (such as the positions of robots, obstacles, and open spaces).\n",
    "\n",
    "**Parameters:**\n",
    "- `world`: A 2D list representing the game grid, where each element in the list is a symbol. \n",
    "**Returns:**\n",
    "- This function does not return anything. It prints the grid row by row, with each row's elements joined into a string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2751,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_world(world):\n",
    "    for row in world:\n",
    "        print(''.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2752,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(world, list)\n",
    "assert all(isinstance(row, list) for row in world)\n",
    "assert all(len(row) == len(world[0]) for row in world)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: euclidean_distance\n",
    "\n",
    "**Description:**\n",
    "This function calculates the Euclidean distance between two points in a 2D grid. It measures the straight-line distance between two positions.\n",
    "\n",
    "**Parameters:**\n",
    "- `pos1`: A tuple representing the coordinates of the first position (x1, y1).\n",
    "- `pos2`: A tuple representing the coordinates of the second position (x2, y2).\n",
    "\n",
    "**Returns:**\n",
    "- A float representing the Euclidean distance between the two positions.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "pos1 = (3, 4)\n",
    "pos2 = (7, 1)\n",
    "distance = euclidean_distance(pos1, pos2)\n",
    "# distance = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2753,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(pos1, pos2):\n",
    "    return math.sqrt((pos1[0] - pos2[0]) ** 2 + (pos1[1] - pos2[1]) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2754,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert euclidean_distance((0, 0), (3, 4)) == 5 \n",
    "assert euclidean_distance((1, 1), (1, 1)) == 0 \n",
    "assert euclidean_distance((2, 2), (5, 6)) == 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: evaluate\n",
    "\n",
    "**Description:**\n",
    "This function calculates an evaluation score for a robot based on its current position relative to the goal and the opponent. The function returns a score that measures how favorable the robot's position is, taking into account the distance to both the goal and the opponent. The score is computed as the Euclidean distance to the opponent minus the Euclidean distance to the goal. This means that a higher score indicates that the robot is farther from the opponent and closer to the goal.\n",
    "\n",
    "**Parameters:**\n",
    "- `robot_pos`: A tuple representing the current position of the robot (x, y).\n",
    "- `goal_pos`: A tuple representing the position of the robot's goal (x, y).\n",
    "- `opponent_pos`: A tuple representing the position of the opponent (x, y).\n",
    "\n",
    "**Returns:**\n",
    "- A float representing the evaluation score. A higher score indicates a better position for the robot in terms of achieving the goal and avoiding the opponent.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "robot_pos = (3, 4)\n",
    "goal_pos = (10, 10)\n",
    "opponent_pos = (5, 5)\n",
    "score = evaluate(robot_pos, goal_pos, opponent_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2755,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(robot_pos, goal_pos, opponent_pos):\n",
    "    return euclidean_distance(robot_pos, opponent_pos) - euclidean_distance(robot_pos, goal_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2756,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert evaluate((0, 0), (3, 4), (6, 8)) == 5\n",
    "assert evaluate((1, 1), (5, 5), (1, 1)) == -math.sqrt(32) \n",
    "assert evaluate((2, 2), (5, 6), (3, 3)) == (math.sqrt(2) - 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: bad_evaluate\n",
    "\n",
    "**Description:**\n",
    "This function evaluates the position of the \"bad\" robot (the opponent) relative to the \"good\" robot. It aims to score the \"bad\" robot's position based on how close it is to the \"good\" robot, as the \"bad\" robot's goal is usually to catch or block the \"good\" robot. This function could focus on maximizing the proximity to the \"good\" robot to increase the chances of catching it.\n",
    "\n",
    "**Parameters:**\n",
    "- `start`: A tuple representing the current position of the \"bad\" robot (x, y).\n",
    "- `opponent`: A tuple representing the position of the \"good\" robot (x, y).\n",
    "\n",
    "**Returns:**\n",
    "- A float representing the evaluation score. A higher score indicates that the \"bad\" robot is closer to the \"good\" robot, making it more advantageous for the \"bad\" robot to catch or block the \"good\" robot.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "bad_robot_pos = (3, 4)\n",
    "good_robot_pos = (10, 10)\n",
    "score = bad_evaluate(bad_robot_pos, good_robot_pos)\n",
    "# The score would reflect how close the bad robot is to the good robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2757,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_evaluate(robot_pos, opponent_pos):\n",
    "    return - euclidean_distance(robot_pos, opponent_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2758,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bad_evaluate((0, 0), (3, 4)) == -5 \n",
    "assert bad_evaluate((1, 1), (1, 1)) == 0  \n",
    "assert bad_evaluate((2, 2), (5, 6)) == -5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: bad_goal_evaluate\n",
    "\n",
    "**Description:**\n",
    "This function evaluates the position of the \"bad\" robot based on two factors: its proximity to the goal and its proximity to the opponent (the \"good\" robot). The function returns a negative score to encourage the \"bad\" robot to minimize its distance to both the goal and the opponent. In this context, the goal is likely to block the opponent from reaching its objective by positioning the \"bad\" robot as a blocker.\n",
    "\n",
    "**Parameters:**\n",
    "- `robot_pos`: A tuple representing the current position of the \"bad\" robot (x, y).\n",
    "- `opponent_pos`: A tuple representing the position of the \"good\" robot (x, y).\n",
    "- `goal_pos`: A tuple representing the position of the goal (x, y).\n",
    "\n",
    "**Returns:**\n",
    "- A negative float score representing the combined distances from the \"bad\" robot to the goal and to the opponent. A higher (less negative) score indicates a better position for blocking the opponent and approaching the goal.\n",
    "\n",
    "**Formula:**\n",
    "The evaluation is calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_goal_evaluate(robot_pos, opponent_pos, goal_pos):\n",
    "    return - euclidean_distance(robot_pos, goal_pos) - euclidean_distance(robot_pos, opponent_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2760,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bad_goal_evaluate((0, 0), (3, 4), (6, 8)) == -10 - 5\n",
    "assert bad_goal_evaluate((1, 1), (1, 1), (5, 5)) == -math.sqrt(32)\n",
    "assert bad_goal_evaluate((2, 2), (5, 6), (3, 3)) == -(5 + math.sqrt(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Function: cal_evaluate\n",
    "\n",
    "**Description:**\n",
    "This function calculates the evaluation score for the robot based on its role (good or bad) and the current game state (start, goal, opponent positions). For a \"good\" robot, it uses the `evaluate` function, while for a \"bad\" robot, it uses either `bad_evaluate` or `bad_goal_evaluate` based on the evaluation argument.\n",
    "\n",
    "**Parameters:**\n",
    "- `role`: A string representing the robot‚Äôs role ('good' or 'bad').\n",
    "- `start`: A tuple representing the current position of the robot.\n",
    "- `goal`: A tuple representing the goal position.\n",
    "- `opponent`: A tuple representing the opponent‚Äôs position.\n",
    "- `bad_evaluate_arg`: A string determining the evaluation strategy for the \"bad\" robot (default is 'opponent_oriented').\n",
    "\n",
    "**Returns:**\n",
    "- A tuple where the first element is the evaluation score and the second is the robot‚Äôs current position.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "cal_evaluate('good', (1, 1), (10, 10), (5, 5))\n",
    "# This will return the evaluation score for a \"good\" robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2761,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_evaluate(role, start, goal, opponent, bad_evaluate_arg = 'opponent_oriented'):\n",
    "    if role == True:\n",
    "        return evaluate(start, goal, opponent),start\n",
    "    elif bad_evaluate_arg == 'opponent_oriented':\n",
    "        # print(f'start:{start}, opponent:{opponent}')\n",
    "        return bad_evaluate(start, opponent), start\n",
    "    else:\n",
    "        return bad_goal_evaluate(start, opponent, goal), start            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2762,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cal_evaluate(True, (0, 0), (3, 4), (6, 8)) == (5, (0, 0))\n",
    "assert cal_evaluate(False, (1, 1), (5, 5), (1, 1)) == (0, (1, 1))\n",
    "assert cal_evaluate(False, (2, 2), (5, 6), (3, 3), 'goal_oriented') == (-5 - math.sqrt(2), (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: generate_legal_moves\n",
    "\n",
    "**Description:**\n",
    "This function generates all possible legal moves for a robot from its current position on a 2D grid (world). It checks the surrounding positions to ensure that the robot does not move out of bounds or into obstacles (represented by `'‚¨õ'`). The function returns a list of valid positions to which the robot can move.\n",
    "\n",
    "**Parameters:**\n",
    "- `world`: A 2D list representing the game grid, where different symbols represent open space, obstacles, and possibly other elements.\n",
    "- `start`: A tuple representing the robot‚Äôs current position (x, y).\n",
    "\n",
    "**Returns:**\n",
    "- A list of tuples, each representing a valid new position that the robot can move to from its current position. If no valid moves are found, the list will be empty.\n",
    "\n",
    "**Logic:**\n",
    "1. For each possible move direction in `MOVES`, the function calculates the new position.\n",
    "2. It checks whether the new position is within the boundaries of the world grid and whether the position is not an obstacle (`'‚¨õ'`).\n",
    "3. Valid positions are appended to the list of legal moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2763,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_legal_moves(world, start):\n",
    "    legal_moves = []\n",
    "    for move in MOVES:\n",
    "        new_position = (start[0] + move[0], start[1] + move[1])\n",
    "        new_r, new_c = new_position\n",
    "        if 0 <= new_r < len(world) and 0 <= new_c < len(world[0]) and world[new_r][new_c] != '‚¨õ':\n",
    "            legal_moves.append(new_position)\n",
    "    return legal_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2764,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert generate_legal_moves(world, (0, 0)) == [(1, 0), (0, 1)]\n",
    "assert generate_legal_moves(world, (2, 2)) == [(2, 1), (3, 2), (2, 3), (1, 2)]\n",
    "assert generate_legal_moves(world, (0, 1)) == [(0, 0), (1, 1), (0, 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: generate_legal_random_moves\n",
    "\n",
    "**Description:**\n",
    "This function generates a random legal move for a robot from its current position on a 2D grid (`world`). It randomly selects a direction from the available moves (stored in `MOVES`) and checks if the move is within bounds and not blocked by an obstacle (represented by `'‚¨õ'`). The function will continue choosing random moves until it finds a valid move or exhausts all possible options. If no valid moves are found, the robot stays in its current position.\n",
    "\n",
    "**Parameters:**\n",
    "- `world`: A 2D list representing the game grid, where different symbols represent open space, obstacles, and possibly other elements.\n",
    "- `current`: A tuple representing the robot‚Äôs current position (x, y).\n",
    "\n",
    "**Returns:**\n",
    "- A tuple representing the new position of the robot after making a legal random move. If no valid moves are found, the function returns the robot's current position.\n",
    "\n",
    "**Logic:**\n",
    "1. A copy of all available moves is created using `deepcopy(MOVES)`.\n",
    "2. A random move is selected from the available moves, and the potential new position is calculated.\n",
    "3. The function checks if the new position is within bounds and does not land on an obstacle (`'‚¨õ'`).\n",
    "4. If the new position is valid, the function returns it. If not, it removes the move from the list of possible moves‚Äã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2765,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_legal_random_moves(world, current):\n",
    "    unmoved = deepcopy(MOVES)\n",
    "    new_position = current\n",
    "    while len(unmoved) > 0:\n",
    "        move = random.choice(unmoved)\n",
    "        unmoved.remove(move)\n",
    "        potential_position = (current[0] + move[0], current[1] + move[1])\n",
    "        new_r, new_c = potential_position\n",
    "        if new_r < 0 or new_r >= len(world) or new_c < 0 or new_c >= len(world[0]):\n",
    "            continue\n",
    "        if world[new_r][new_c] == '‚¨õ':     \n",
    "            continue\n",
    "        else :\n",
    "            new_position = potential_position\n",
    "            break\n",
    "    return new_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "print(generate_legal_random_moves(world, (4, 2)))\n",
    "assert generate_legal_random_moves(world, (0, 0)) in [(1, 0), (0, 1)]\n",
    "assert generate_legal_random_moves(world, (2, 2)) in [(3, 2), (1, 0), (2, 1), (2, 3), (1, 2)]\n",
    "assert generate_legal_random_moves(world, (4, 2)) in [(5, 2), (4, 1), (4, 3),(3, 2), (2, 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: minimax\n",
    "\n",
    "**Description:**\n",
    "This function implements the minimax algorithm, which is used for decision-making in adversarial games. The function evaluates all possible future game states up to a certain depth, alternating between two players (one trying to maximize the score and the other trying to minimize it). Each player tries to choose the move that is best for their respective objective. The \"good\" player tries to reach the goal while avoiding the opponent, and the \"bad\" player attempts to prevent the \"good\" player from succeeding.\n",
    "\n",
    "**Parameters:**\n",
    "- `world`: A 2D list representing the game grid, where different symbols represent open spaces, obstacles, and other elements.\n",
    "- `start`: A tuple representing the current position of the robot whose turn it is to move.\n",
    "- `goal`: A tuple representing the goal position of the \"good\" robot.\n",
    "- `opponent`: A tuple representing the current position of the opposing robot.\n",
    "- `role`: A string representing the current player ('good' or 'bad').\n",
    "- `maximizing_player`: A boolean indicating whether the current player is the maximizing player (True for the \"good\" robot, False for the \"bad\" robot).\n",
    "- `depth`: An integer indicating the depth of the search. A higher depth allows for more turns to be considered in advance, but increases computational cost.\n",
    "- `bad_evaluate_arg`: A string specifying the evaluation strategy for the \"bad\" robot (default is 'opponent_oriented').\n",
    "\n",
    "**Returns:**\n",
    "- A tuple containing:\n",
    "  - The best evaluation score from the current game state.\n",
    "  - The corresponding move (a tuple representing the new position) that produces the best score.\n",
    "\n",
    "**Logic:**\n",
    "1. **Base Case**: The recursion stops when the depth reaches 0, or if the current robot reaches the goal. At this point, the evaluation function is called to score the current game state.\n",
    "2. **Maximizing and Minimizing**: The algorithm alternates between the two players, with the \"good\" robot trying to maximize the evaluation score and the \"bad\" robot trying to minimize it.\n",
    "3. **Recursion**: The function recursively explores all legal moves, switching between players at each step, and returns the best possible move for the current player.\n",
    "4. **Legal Moves**: Legal moves for the current robot are generated based on its position and the game grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2767,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(world, start, goal, opponent, role, maximizing_player, depth=2, bad_evaluate_arg=\"opponent_oriented\"):\n",
    "    if depth == 0 or start == goal:\n",
    "        return cal_evaluate(role, start, goal, opponent, bad_evaluate_arg)\n",
    "\n",
    "    best_move = None\n",
    "    best_value = float('-inf') if maximizing_player else float('inf')\n",
    "\n",
    "    legal_moves = generate_legal_moves(world, start)\n",
    "    for move in legal_moves:\n",
    "\n",
    "        eval, _ = minimax(world, opponent, goal, move, not role, not maximizing_player, depth - 1, bad_evaluate_arg)\n",
    "        if (maximizing_player and eval > best_value) or (not maximizing_player and eval < best_value):\n",
    "            best_value, best_move = eval, move\n",
    "    \n",
    "    return best_value, best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2768,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert minimax(world, (0, 0), (4, 4), (3, 3), True, True, depth=2) == (-2.1715728752538097, (1, 0))\n",
    "assert minimax(world, (1, 1), (4, 4), (2, 2), False, True, depth=2) == (-2.0, (2, 1))\n",
    "assert minimax(world, (3, 3), (0, 0), (4, 4), True, True, depth=1) == (-1.0, (4, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: run_strategy\n",
    "\n",
    "**Description:**\n",
    "This function handles the movement strategy of a robot based on a given strategy type, such as random movement or the minimax algorithm. It evaluates possible moves and returns the next valid position for the robot based on the chosen strategy.\n",
    "\n",
    "**Parameters:**\n",
    "- `_world`: A 2D list representing the game grid, where different symbols represent open space, obstacles, and other elements.\n",
    "- `start`: A tuple representing the robot‚Äôs current position (x, y).\n",
    "- `goal`: A tuple representing the goal position of the \"good\" robot (x, y).\n",
    "- `strategy`: A string indicating the movement strategy. It can be `\"random_strategy\"` for random movement or `\"MINIMAX\"` for the minimax decision-making process.\n",
    "- `role`: A boolean or string representing the role of the robot. If `True`, the robot is the \"good\" robot (ü§ñ). If `False`, it is the \"bad\" robot (üëæ).\n",
    "- `opponent`: A tuple representing the opponent robot's position (x, y). It defaults to `None` if no opponent is provided.\n",
    "- `depth`: An integer specifying the depth of the minimax search. Default value is 2.\n",
    "- `bad_evaluate_arg`: A string specifying the evaluation strategy for the \"bad\" robot. Default value is `\"opponent_oriented\"`.\n",
    "\n",
    "**Returns:**\n",
    "- A tuple representing the new position of the robot after applying the chosen strategy.\n",
    "\n",
    "**Logic:**\n",
    "1. **Random Strategy**: \n",
    "   - If the strategy is `\"random_strategy\"`, the function calls `generate_legal_random_moves` to choose a legal random move from the robot‚Äôs current position.\n",
    "2. **Minimax Strategy**: \n",
    "   - If the strategy is `\"MINIMAX\"`, the function uses the `minimax` algorithm to compute the best possible move for the robot based on its role and depth.\n",
    "3. **Update Position**: \n",
    "   - The function updates the robot's position on the grid. If the robot is the \"good\" robot, it marks its previous position as `üü©` and the new position as `ü§ñ`. If it is the \"bad\" robot, it marks the previous position as `üü•` and the new position as `üëæ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2769,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_strategy(_world, start, goal, strategy, role, opponent=None, depth=2, bad_evaluate_arg=\"opponent_oriented\"):\n",
    "    current = start\n",
    "    new_position = start\n",
    "\n",
    "    if strategy == \"random_strategy\":\n",
    "        new_position = generate_legal_random_moves(_world, current)\n",
    "\n",
    "    elif strategy == \"MINIMAX\":\n",
    "        eval, best_move = minimax(_world, start, goal, opponent, role, True, depth=depth, bad_evaluate_arg=bad_evaluate_arg)\n",
    "        new_position = best_move\n",
    "    if _world[current[0]][current[1]] != '‚ù§Ô∏è' and _world[current[0]][current[1]] != 'üëæ' and _world[current[0]][current[1]] != 'ü§ñ' and _world[current[0]][current[1]] != 'üü©' and _world[current[0]][current[1]] != 'üü•':\n",
    "        if role == True:\n",
    "            _world[current[0]][current[1]] = 'üü©'\n",
    "        else:\n",
    "            _world[current[0]][current[1]] = 'üü•'\n",
    "    return new_position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2770,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert run_strategy(world, (0, 0), goal, \"random_strategy\", True, (0, 20)) in [(0, 1), (1, 0)]\n",
    "assert run_strategy(world, (0, 0), goal, \"MINIMAX\", True, (0, 20)) in [(1, 0), (0, 1)]\n",
    "assert run_strategy(world, (0, 0), goal, \"MINIMAX\", True, (0, 20), 4) in [(1, 0), (0, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: run_robot_game\n",
    "\n",
    "**Description:**\n",
    "This function simulates a turn-based game where two robots (\"good\" and \"bad\") move across a grid towards their respective goals or objectives. The \"good\" robot (ü§ñ) tries to reach the goal, while the \"bad\" robot (üëæ) tries to block or catch the \"good\" robot. Each robot uses a given strategy (random or minimax) to decide its movement. The game continues for a fixed number of turns or until one robot reaches its objective.\n",
    "\n",
    "**Parameters:**\n",
    "- `_world`: A 2D list representing the game grid, where different symbols represent open space, obstacles, and other elements.\n",
    "- `good_start`: A tuple representing the starting position of the \"good\" robot (x, y).\n",
    "- `bad_start`: A tuple representing the starting position of the \"bad\" robot (x, y).\n",
    "- `goal`: A tuple representing the goal position of the \"good\" robot (x, y).\n",
    "- `good_strategy`: A string representing the movement strategy for the \"good\" robot. It can be `\"random_strategy\"` or `\"MINIMAX\"`.\n",
    "- `bad_strategy`: A string representing the movement strategy for the \"bad\" robot. It can be `\"random_strategy\"` or `\"MINIMAX\"`.\n",
    "- `bad_strategy_depth`: An integer specifying the search depth for the minimax algorithm when the \"bad\" robot is using it. Default is 2.\n",
    "- `good_strategy_depth`: An integer specifying the search depth for the minimax algorithm when the \"good\" robot is using it. Default is 2.\n",
    "- `bad_evaluate_arg`: A string specifying the evaluation strategy for the \"bad\" robot. Default is `\"opponent_oriented\"`.\n",
    "\n",
    "**Returns:**\n",
    "- The function does not return any values. It prints the final state of the game grid and the result of the game (either the \"good\" robot reaches the goal or the \"bad\" robot catches the \"good\" robot).\n",
    "\n",
    "**Logic:**\n",
    "1. **Game Loop**: The game runs in a loop for a maximum of 82 turns. During each turn:\n",
    "    - The \"good\" robot moves according to its strategy. If it reaches the goal, the game ends with a victory message.\n",
    "    - The \"bad\" robot moves according to its strategy. If it catches the \"good\" robot (i.e., moves to the same position), the game ends with a message indicating the \"good\" robot has been caught.\n",
    "2. **Strategy Execution**: \n",
    "    - Each robot's movement is determined by calling the `run_strategy` function, which takes into account the robot's strategy (random or minimax), the game state, and the position of the opponent.\n",
    "3. **Termination Conditions**: \n",
    "    - The game ends if the \"good\" robot reaches the goal, if the \"bad\" robot catches the \"good\" robot, or if the maximum number of turns (82) is reached.\n",
    "4. **World Update**: \n",
    "    - After each move, the game grid is updated to reflect the robot's new position, and the world is printed at the end of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2771,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_robot_game(_world, good_start, bad_start, goal, good_strategy, bad_strategy, bad_strategy_depth = 2, good_strategy_depth = 2, bad_evaluate_arg=\"opponent_oriented\"): # Amend argument list and description above as you see fit\n",
    "    turn_count = 0\n",
    "    max_turns = 82\n",
    "    while turn_count < max_turns:\n",
    "        if bad_start == good_start:\n",
    "            print(\"Robot was caught by the bad robot!\")\n",
    "            break\n",
    "        if good_start == goal:\n",
    "            print(\"Robot reached the goal!\")\n",
    "            break\n",
    "        good_start = run_strategy(_world, good_start, goal, good_strategy, True, bad_start, good_strategy_depth)\n",
    "        bad_start = run_strategy(_world, bad_start, goal, bad_strategy, False, good_start, bad_strategy_depth, bad_evaluate_arg)\n",
    "        turn_count += 1\n",
    "    print_world(_world)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot reached the goal!\n",
      "üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©‚ù§Ô∏è\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•üü•üü•\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•üü•üü•üü•\n",
      "ü§ñ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•üëæ\n"
     ]
    }
   ],
   "source": [
    "# Modify arguments, but when you uncomment the line below, it should ONLY print out a nice view of the world when the game is over\n",
    "_world = deepcopy(world)\n",
    "result_1 = run_robot_game(_world, good_start, bad_start, goal, good_strategy = 'MINIMAX', bad_strategy = 'random_strategy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #2\n",
    "\n",
    "\n",
    "Play the game again, but in this problem, 'ü§ñ' and 'üëæ' both use MINIMAX with a depth of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot reached the goal!\n",
      "üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©‚ù§Ô∏è\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•üü•üü•üü•üü•üü•üü•üü•üü•üü•‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•üü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "ü§ñ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•üü•üü•üü•üü•üü•üü•üü•üü•üëæ\n"
     ]
    }
   ],
   "source": [
    "# Modify arguments, but when you uncomment the line below, it should ONLY print out a nice view of the world when the game is over\n",
    "_world_2 = deepcopy(world)\n",
    "result_2 = run_robot_game(_world_2, good_start, bad_start, goal, good_strategy = \"MINIMAX\", bad_strategy = \"MINIMAX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #3\n",
    "\n",
    "\n",
    "Play the game again, but in this problem 'ü§ñ' uses a depth of 2; 'üëæ' uses a depth of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2774,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot reached the goal!\n",
      "üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©‚ù§Ô∏è\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•üü•üü•üü•üü•üü•üü•üü•üü•üü•‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•üü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú\n",
      "ü§ñ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•üü•üü•üü•üü•üü•üü•üü•üü•üëæ\n"
     ]
    }
   ],
   "source": [
    "# # Add your arguments, but when you uncomment the line below, it should ONLY print out a nice view of the world when the game is over\n",
    "_world_3 = deepcopy(world)\n",
    "result_3 = run_robot_game(_world_3, good_start, bad_start, goal, good_strategy = \"MINIMAX\", bad_strategy = \"MINIMAX\", bad_strategy_depth=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #4\n",
    "\n",
    "\n",
    "Play the game again, but in this problem, 'ü§ñ' and 'üëæ' both use a depth of 4 and utility function of 'üëæ' = - Euclidean distance to '‚ù§Ô∏è' - Euclidean distance to 'ü§ñ' (it now knows the '‚ù§Ô∏è' means something to 'ü§ñ')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot was caught by the bad robot!\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚ù§Ô∏è\n",
      "üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü©üü•üü•\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ‚¨õ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•‚¨ú\n",
      "üü©‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüü•üü•\n",
      "ü§ñ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú‚¨úüëæ\n"
     ]
    }
   ],
   "source": [
    "# # Add your arguments, but this should ONLY print out a nice view of the world\n",
    "_world_4 = deepcopy(world)\n",
    "result_4 = run_robot_game(_world_4, good_start, bad_start, goal, good_strategy = \"MINIMAX\", bad_strategy = \"MINIMAX\", bad_strategy_depth=4, good_strategy_depth=4, bad_evaluate_arg=\"goal_oriented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Question | Comment | \n",
    "|------|------|\n",
    "|Did knowledge of 'ü§ñ' trying to get to '‚ù§Ô∏è' help 'üëæ'? | It can help üëæ get closer to ü§ñ. The reason is as follows: this utility function allows us to predict where ü§ñ will appear, i.e., in the vicinity of the GOAL, and at the same time, this utility function takes into account not only the defensive target but also the pursuing target at the position where ü§ñ will appear. From Problem 4, it can be seen that üëæ has considered the goal and arrived at the goal earlier, so the knowledge is valid for chasing ü§ñ.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Re-read the general instructions provided above, and\n",
    "2. Hit \"Kernel\"->\"Restart & Run All\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
